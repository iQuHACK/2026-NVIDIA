{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cudaq\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import Counter\n",
    "from scipy.optimize import minimize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-mts",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_energy(sequence):\n",
    "    N = len(sequence)\n",
    "    energy = 0\n",
    "    for k in range(1, N):\n",
    "        C_k = sum(sequence[i] * sequence[i + k] for i in range(N - k))\n",
    "        energy += C_k ** 2\n",
    "    return energy\n",
    "\n",
    "\n",
    "def bitstring_to_sequence(bitstring):\n",
    "    return [1 if b == '0' else -1 for b in bitstring]\n",
    "\n",
    "\n",
    "def sequence_to_bitstring(sequence):\n",
    "    return ''.join('0' if s == 1 else '1' for s in sequence)\n",
    "\n",
    "\n",
    "def random_sequence(N):\n",
    "    return [random.choice([1, -1]) for _ in range(N)]\n",
    "\n",
    "\n",
    "def combine(parent1, parent2):\n",
    "    child = []\n",
    "    for i in range(len(parent1)):\n",
    "        if random.random() < 0.5:\n",
    "            child.append(parent1[i])\n",
    "        else:\n",
    "            child.append(parent2[i])\n",
    "    return child\n",
    "\n",
    "\n",
    "def mutate(sequence, p_mutate=0.1):\n",
    "    mutated = sequence.copy()\n",
    "    for i in range(len(mutated)):\n",
    "        if random.random() < p_mutate:\n",
    "            mutated[i] *= -1\n",
    "    return mutated\n",
    "\n",
    "\n",
    "def tabu_search(initial_sequence, max_iterations=100, tabu_tenure=7):\n",
    "    N = len(initial_sequence)\n",
    "    current = initial_sequence.copy()\n",
    "    current_energy = compute_energy(current)\n",
    "    \n",
    "    best = current.copy()\n",
    "    best_energy = current_energy\n",
    "    \n",
    "    tabu_list = {}\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        best_neighbor = None\n",
    "        best_neighbor_energy = float('inf')\n",
    "        best_move = None\n",
    "        \n",
    "        for i in range(N):\n",
    "            neighbor = current.copy()\n",
    "            neighbor[i] *= -1\n",
    "            neighbor_energy = compute_energy(neighbor)\n",
    "            \n",
    "            is_tabu = i in tabu_list and tabu_list[i] > iteration\n",
    "            \n",
    "            if is_tabu and neighbor_energy >= best_energy:\n",
    "                continue\n",
    "            \n",
    "            if neighbor_energy < best_neighbor_energy:\n",
    "                best_neighbor = neighbor\n",
    "                best_neighbor_energy = neighbor_energy\n",
    "                best_move = i\n",
    "        \n",
    "        if best_neighbor is None:\n",
    "            break\n",
    "        \n",
    "        current = best_neighbor\n",
    "        current_energy = best_neighbor_energy\n",
    "        tabu_list[best_move] = iteration + tabu_tenure\n",
    "        \n",
    "        if current_energy < best_energy:\n",
    "            best = current.copy()\n",
    "            best_energy = current_energy\n",
    "    \n",
    "    return best, best_energy\n",
    "\n",
    "\n",
    "def memetic_tabu_search(N, population_size=20, max_generations=50, \n",
    "                        p_mutate=0.1, tabu_iterations=100, initial_population=None):\n",
    "    if initial_population is not None:\n",
    "        population = [seq.copy() for seq in initial_population]\n",
    "    else:\n",
    "        population = [random_sequence(N) for _ in range(population_size)]\n",
    "    \n",
    "    energies = [compute_energy(seq) for seq in population]\n",
    "    \n",
    "    best_idx = np.argmin(energies)\n",
    "    best_sequence = population[best_idx].copy()\n",
    "    best_energy = energies[best_idx]\n",
    "    \n",
    "    energy_history = [best_energy]\n",
    "    \n",
    "    for generation in range(max_generations):\n",
    "        if random.random() < 0.5:\n",
    "            parent1 = random.choice(population)\n",
    "            parent2 = random.choice(population)\n",
    "            child = combine(parent1, parent2)\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "        \n",
    "        if random.random() < p_mutate:\n",
    "            child = mutate(child, p_mutate=0.1)\n",
    "        \n",
    "        improved_child, child_energy = tabu_search(child, max_iterations=tabu_iterations)\n",
    "        \n",
    "        worst_idx = np.argmax(energies)\n",
    "        if child_energy < energies[worst_idx]:\n",
    "            population[worst_idx] = improved_child\n",
    "            energies[worst_idx] = child_energy\n",
    "        \n",
    "        if child_energy < best_energy:\n",
    "            best_sequence = improved_child.copy()\n",
    "            best_energy = child_energy\n",
    "        \n",
    "        energy_history.append(best_energy)\n",
    "    \n",
    "    return best_sequence, best_energy, population, energy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-interactions",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_interactions(N):\n",
    "    G2_weighted = {}\n",
    "    G4_weighted = {}\n",
    "    constant = 0\n",
    "    \n",
    "    for k in range(1, N):\n",
    "        pairs_for_k = [(i, i + k) for i in range(N - k)]\n",
    "        num_pairs = len(pairs_for_k)\n",
    "    \n",
    "        constant += num_pairs\n",
    "        \n",
    "        for idx1 in range(num_pairs):\n",
    "            for idx2 in range(idx1 + 1, num_pairs):\n",
    "                i1, j1 = pairs_for_k[idx1]\n",
    "                i2, j2 = pairs_for_k[idx2]\n",
    "                \n",
    "                indices = tuple(sorted([i1, j1, i2, j2]))\n",
    "                unique_indices = set(indices)\n",
    "                \n",
    "                if len(unique_indices) == 4:\n",
    "                    key = tuple(sorted([i1, j1, i2, j2]))\n",
    "                    G4_weighted[key] = G4_weighted.get(key, 0) + 2\n",
    "                elif len(unique_indices) == 3:\n",
    "                    counts = Counter([i1, j1, i2, j2])\n",
    "                    singles = sorted([idx for idx, cnt in counts.items() if cnt == 1])\n",
    "                    key = tuple(singles)\n",
    "                    G2_weighted[key] = G2_weighted.get(key, 0) + 2\n",
    "                elif len(unique_indices) == 2:\n",
    "                    constant += 2\n",
    "    \n",
    "    return G2_weighted, G4_weighted, constant\n",
    "\n",
    "\n",
    "def verify_hamiltonian_encoding(N, num_samples=100):\n",
    "    G2_weighted, G4_weighted, constant = get_interactions(N)\n",
    "    \n",
    "    all_match = True\n",
    "    max_diff = 0\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        seq = random_sequence(N)\n",
    "        classical_energy = compute_energy(seq)\n",
    "        \n",
    "        hamiltonian_energy = constant\n",
    "        for (i, j), weight in G2_weighted.items():\n",
    "            hamiltonian_energy += weight * seq[i] * seq[j]\n",
    "        for (i, j, k, l), weight in G4_weighted.items():\n",
    "            hamiltonian_energy += weight * seq[i] * seq[j] * seq[k] * seq[l]\n",
    "        \n",
    "        diff = abs(classical_energy - hamiltonian_energy)\n",
    "        max_diff = max(max_diff, diff)\n",
    "        if diff > 1e-10:\n",
    "            all_match = False\n",
    "    \n",
    "    return all_match, max_diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "symmetry-canonicalization",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def canonicalize_sequence(sequence):\n",
    "\n",
    "    seq = list(sequence)\n",
    "    variants = [\n",
    "        seq,\n",
    "        [-s for s in seq],\n",
    "        seq[::-1],\n",
    "        [-s for s in seq[::-1]]\n",
    "    ]\n",
    "    \n",
    "    bitstrings = [sequence_to_bitstring(v) for v in variants]\n",
    "    min_idx = np.argmin(bitstrings)\n",
    "    \n",
    "    return variants[min_idx], bitstrings[min_idx]\n",
    "\n",
    "\n",
    "def canonicalize_bitstring(bitstring):\n",
    "    seq = bitstring_to_sequence(bitstring)\n",
    "    _, canonical_bs = canonicalize_sequence(seq)\n",
    "    return canonical_bs\n",
    "\n",
    "\n",
    "def compute_diversity_metrics(samples_dict):\n",
    "    total_count = sum(samples_dict.values())\n",
    "    num_unique_raw = len(samples_dict)\n",
    "    \n",
    "    probs_raw = np.array(list(samples_dict.values())) / total_count\n",
    "    entropy_raw = -np.sum(probs_raw * np.log2(probs_raw + 1e-12))\n",
    "    \n",
    "    canonical_counts = {}\n",
    "    for bs, count in samples_dict.items():\n",
    "        canon = canonicalize_bitstring(bs)\n",
    "        canonical_counts[canon] = canonical_counts.get(canon, 0) + count\n",
    "    \n",
    "    num_unique_canonical = len(canonical_counts)\n",
    "    probs_canon = np.array(list(canonical_counts.values())) / total_count\n",
    "    entropy_canonical = -np.sum(probs_canon * np.log2(probs_canon + 1e-12))\n",
    "    \n",
    "    return {\n",
    "        'num_unique_raw': num_unique_raw,\n",
    "        'num_unique_canonical': num_unique_canonical,\n",
    "        'entropy_raw': entropy_raw,\n",
    "        'entropy_canonical': entropy_canonical,\n",
    "        'symmetry_collapse_ratio': num_unique_canonical / max(num_unique_raw, 1)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cvar-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cvar(energies, counts, alpha=0.2):\n",
    "   \n",
    "    all_energies = []\n",
    "    for e, c in zip(energies, counts):\n",
    "        all_energies.extend([e] * c)\n",
    "    \n",
    "    all_energies = np.array(all_energies)\n",
    "    total = len(all_energies)\n",
    "    sorted_energies = np.sort(all_energies)\n",
    "    k = max(1, int(alpha * total))\n",
    "    \n",
    "    return np.mean(sorted_energies[:k])\n",
    "\n",
    "\n",
    "def compute_best_k_mean(energies, counts, k=10):\n",
    "    sorted_pairs = sorted(zip(energies, counts), key=lambda x: x[0])\n",
    "    best_energies = [e for e, c in sorted_pairs[:k]]\n",
    "    return np.mean(best_energies) if best_energies else float('inf')\n",
    "\n",
    "\n",
    "def compute_sample_statistics(energies, counts, alpha=0.2):\n",
    "    all_energies = []\n",
    "    for e, c in zip(energies, counts):\n",
    "        all_energies.extend([e] * c)\n",
    "    \n",
    "    all_energies = np.array(all_energies)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(all_energies),\n",
    "        'median': np.median(all_energies),\n",
    "        'min': np.min(all_energies),\n",
    "        'max': np.max(all_energies),\n",
    "        'std': np.std(all_energies),\n",
    "        'cvar': compute_cvar(energies, counts, alpha),\n",
    "        'best_10_mean': compute_best_k_mean(energies, counts, k=10),\n",
    "        'num_unique': len(energies)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qaoa-circuit-weighted",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cudaq.kernel\n",
    "def qaoa_circuit(N: int, p: int, \n",
    "                          G2_indices: list[list[int]], G2_weights: list[float],\n",
    "                          G4_indices: list[list[int]], G4_weights: list[float],\n",
    "                          gammas: list[float], betas: list[float]):\n",
    "  \n",
    "    reg = cudaq.qvector(N)\n",
    "    h(reg)\n",
    "    \n",
    "    for layer in range(p):\n",
    "        gamma = gammas[layer]\n",
    "        beta = betas[layer]\n",
    "        \n",
    "        for idx in range(len(G2_indices)):\n",
    "            pair = G2_indices[idx]\n",
    "            weight = G2_weights[idx]\n",
    "            i = pair[0]\n",
    "            j = pair[1]\n",
    "            angle = 2.0 * gamma * weight\n",
    "            x.ctrl(reg[i], reg[j])\n",
    "            rz(angle, reg[j])\n",
    "            x.ctrl(reg[i], reg[j])\n",
    "        \n",
    "        for idx in range(len(G4_indices)):\n",
    "            quad = G4_indices[idx]\n",
    "            weight = G4_weights[idx]\n",
    "            i = quad[0]\n",
    "            t = quad[1]\n",
    "            k = quad[2]\n",
    "            l = quad[3]\n",
    "            angle = 2.0 * gamma * weight\n",
    "            x.ctrl(reg[i], reg[t])\n",
    "            x.ctrl(reg[t], reg[k])\n",
    "            x.ctrl(reg[k], reg[l])\n",
    "            rz(angle, reg[l])\n",
    "            x.ctrl(reg[k], reg[l])\n",
    "            x.ctrl(reg[t], reg[k])\n",
    "            x.ctrl(reg[i], reg[t])\n",
    "        \n",
    "        for q in range(N):\n",
    "            rx(2.0 * beta, reg[q])\n",
    "\n",
    "\n",
    "def prepare_circuit_data(N):\n",
    "    G2_weighted, G4_weighted, constant = get_interactions(N)\n",
    "    \n",
    "    G2_indices = [list(k) for k in G2_weighted.keys()]\n",
    "    G2_weights = [float(v) for v in G2_weighted.values()]\n",
    "    \n",
    "    G4_indices = [list(k) for k in G4_weighted.keys()]\n",
    "    G4_weights = [float(v) for v in G4_weighted.values()]\n",
    "    \n",
    "    return G2_indices, G2_weights, G4_indices, G4_weights, constant\n",
    "\n",
    "for test_N in [5, 10, 15]:\n",
    "    G2_i, G2_w, G4_i, G4_w, const = prepare_circuit_data(test_N)\n",
    "    print(f\"  N={test_N}: {len(G2_i)} 2-body, {len(G4_i)} 4-body, const={const}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-qaoa-optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class QAOAOptimizer:\n",
    "    def __init__(self, N, p=1, shots=1000, alpha=0.2, objective='cvar', verbose=True):\n",
    "        self.N = N\n",
    "        self.p = p\n",
    "        self.shots = shots\n",
    "        self.alpha = alpha\n",
    "        self.objective = objective\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.G2_indices, self.G2_weights, self.G4_indices, self.G4_weights, self.constant = \\\n",
    "            prepare_circuit_data(N)\n",
    "        \n",
    "        self.eval_count = 0\n",
    "        self.history = []\n",
    "        self.best_params = None\n",
    "        self.best_objective = float('inf')\n",
    "        self.all_samples = {}\n",
    "    \n",
    "    def evaluate(self, params, confirm_shots=None):\n",
    "        self.eval_count += 1\n",
    "        \n",
    "        gammas = list(params[:self.p])\n",
    "        betas = list(params[self.p:])\n",
    "        shots_to_use = confirm_shots if confirm_shots else self.shots\n",
    "        \n",
    "        result = cudaq.sample(\n",
    "            qaoa_circuit_weighted,\n",
    "            self.N, self.p,\n",
    "            self.G2_indices, self.G2_weights,\n",
    "            self.G4_indices, self.G4_weights,\n",
    "            gammas, betas,\n",
    "            shots_count=shots_to_use\n",
    "        )\n",
    "        \n",
    "        energies = []\n",
    "        counts = []\n",
    "        \n",
    "        for bitstring in result:\n",
    "            count = result[bitstring]\n",
    "            sequence = bitstring_to_sequence(bitstring)\n",
    "            energy = compute_energy(sequence)\n",
    "            \n",
    "            energies.append(energy)\n",
    "            counts.append(count)\n",
    "            \n",
    "            if bitstring not in self.all_samples:\n",
    "                self.all_samples[bitstring] = {'count': 0, 'energy': energy}\n",
    "            self.all_samples[bitstring]['count'] += count\n",
    "        \n",
    "        stats = compute_sample_statistics(energies, counts, self.alpha)\n",
    "        \n",
    "        if self.objective == 'cvar':\n",
    "            obj_value = stats['cvar']\n",
    "        elif self.objective == 'best_k':\n",
    "            obj_value = stats['best_10_mean']\n",
    "        else:\n",
    "            obj_value = stats['mean']\n",
    "        \n",
    "        if obj_value < self.best_objective:\n",
    "            self.best_objective = obj_value\n",
    "            self.best_params = params.copy()\n",
    "        \n",
    "        self.history.append((params.copy(), obj_value, stats))\n",
    "        \n",
    "        if self.verbose and self.eval_count % 10 == 0:\n",
    "            print(f\"    Eval {self.eval_count}: obj={obj_value:.2f}, \"\n",
    "                  f\"mean={stats['mean']:.2f}, min={stats['min']}, CVaR={stats['cvar']:.2f}\")\n",
    "        \n",
    "        return obj_value\n",
    "    \n",
    "    def optimize_two_stage(self, \n",
    "                           gamma_range=(-np.pi, np.pi),\n",
    "                           beta_range=(-np.pi/2, np.pi/2),\n",
    "                           coarse_grid=8, fine_grid=5,\n",
    "                           top_k_refine=3, confirm_shots_multiplier=3):\n",
    "        \n",
    "        print(f\"\\n  Stage 1: Coarse grid ({coarse_grid}x{coarse_grid})\")\n",
    "        \n",
    "        gammas = np.linspace(gamma_range[0], gamma_range[1], coarse_grid)\n",
    "        betas = np.linspace(beta_range[0], beta_range[1], coarse_grid)\n",
    "        gamma_step = gammas[1] - gammas[0] if len(gammas) > 1 else 0.5\n",
    "        beta_step = betas[1] - betas[0] if len(betas) > 1 else 0.25\n",
    "        \n",
    "        coarse_results = []\n",
    "        \n",
    "        for i, gamma in enumerate(gammas):\n",
    "            for beta in betas:\n",
    "                params = np.array([gamma, beta])\n",
    "                obj = self.evaluate(params)\n",
    "                coarse_results.append((params.copy(), obj))\n",
    "            \n",
    "            if (i + 1) % (coarse_grid // 4) == 0:\n",
    "                print(f\"    Coarse progress: {(i + 1) / coarse_grid * 100:.0f}%\")\n",
    "        \n",
    "        coarse_results.sort(key=lambda x: x[1])\n",
    "        print(f\"  Top-3 coarse: {[(f'({r[0][0]:.2f},{r[0][1]:.2f})', f'{r[1]:.1f}') for r in coarse_results[:3]]}\")\n",
    "        \n",
    "        print(f\"\\n  Stage 2: Fine grid ({fine_grid}x{fine_grid}) around top-{top_k_refine}\")\n",
    "        \n",
    "        fine_results = []\n",
    "        \n",
    "        for coarse_params, _ in coarse_results[:top_k_refine]:\n",
    "            g_center, b_center = coarse_params\n",
    "            \n",
    "            g_fine = np.linspace(g_center - gamma_step/2, g_center + gamma_step/2, fine_grid)\n",
    "            b_fine = np.linspace(b_center - beta_step/2, b_center + beta_step/2, fine_grid)\n",
    "            \n",
    "            for gamma in g_fine:\n",
    "                for beta in b_fine:\n",
    "                    params = np.array([gamma, beta])\n",
    "                    obj = self.evaluate(params)\n",
    "                    fine_results.append((params.copy(), obj))\n",
    "        \n",
    "        fine_results.sort(key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"\\n  Stage 3: Confirming with {self.shots * confirm_shots_multiplier} shots\")\n",
    "        \n",
    "        best_candidate = fine_results[0][0]\n",
    "        confirmed_obj = self.evaluate(best_candidate, \n",
    "                                      confirm_shots=self.shots * confirm_shots_multiplier)\n",
    "        \n",
    "        print(f\"  Confirmed: gamma={best_candidate[0]:.4f}, beta={best_candidate[1]:.4f}, obj={confirmed_obj:.2f}\")\n",
    "        \n",
    "        return self.best_params, self.best_objective\n",
    "    \n",
    "    def extract_diverse_seeds(self, population_size, verbose=True):\n",
    "        samples_dict = {bs: data['count'] for bs, data in self.all_samples.items()}\n",
    "        metrics = compute_diversity_metrics(samples_dict)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n  Diversity: {metrics['num_unique_raw']} raw -> {metrics['num_unique_canonical']} canonical\")\n",
    "        \n",
    "        canonical_map = {}\n",
    "        for bitstring, data in self.all_samples.items():\n",
    "            seq = bitstring_to_sequence(bitstring)\n",
    "            energy = data['energy']\n",
    "            count = data['count']\n",
    "            _, canon_bs = canonicalize_sequence(seq)\n",
    "            \n",
    "            if canon_bs not in canonical_map:\n",
    "                canonical_map[canon_bs] = (seq, energy, count)\n",
    "            else:\n",
    "                existing = canonical_map[canon_bs]\n",
    "                if count > existing[2] or (count == existing[2] and energy < existing[1]):\n",
    "                    canonical_map[canon_bs] = (seq, energy, count)\n",
    "        \n",
    "        sorted_canonical = sorted(canonical_map.values(), key=lambda x: x[1])\n",
    "        \n",
    "        population = []\n",
    "        energies = []\n",
    "        \n",
    "        for seq, energy, count in sorted_canonical:\n",
    "            if len(population) >= population_size:\n",
    "                break\n",
    "            population.append(list(seq))\n",
    "            energies.append(energy)\n",
    "        \n",
    "        num_from_qaoa = len(population)\n",
    "        while len(population) < population_size:\n",
    "            new_seq = random_sequence(self.N)\n",
    "            population.append(new_seq)\n",
    "            energies.append(compute_energy(new_seq))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Seeds: {num_from_qaoa} from QAOA, {population_size - num_from_qaoa} random\")\n",
    "            print(f\"  Energy range: [{min(energies)}, {max(energies)}], mean={np.mean(energies):.1f}\")\n",
    "        \n",
    "        metrics['num_from_qaoa'] = num_from_qaoa\n",
    "        return population, energies, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-qaoa-mts",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def qaoa_enhanced_mts(N, p=1, population_size=20, max_generations=30,\n",
    "                               qaoa_shots=1000, tabu_iterations=50,\n",
    "                               alpha=0.2, objective='cvar',\n",
    "                               coarse_grid=8, fine_grid=5, verbose=True):\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"QAOA-Enhanced MTS for LABS (N={N}, p={p}, obj={objective})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Step 1: QAOA Optimization\n",
    "    print(f\"\\n[Step 1] QAOA Parameter Optimization\")\n",
    "    \n",
    "    qaoa = QAOAOptimizer(\n",
    "        N=N, p=p, shots=qaoa_shots, alpha=alpha, objective=objective, verbose=verbose\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_params, best_obj = qaoa.optimize_two_stage(\n",
    "        coarse_grid=coarse_grid, fine_grid=fine_grid, top_k_refine=3\n",
    "    )\n",
    "    qaoa_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n  QAOA done: {qaoa.eval_count} evals in {qaoa_time:.2f}s, best {objective}={best_obj:.2f}\")\n",
    "    \n",
    "    results['qaoa_time'] = qaoa_time\n",
    "    results['qaoa_best_obj'] = best_obj\n",
    "    results['qaoa_best_params'] = best_params\n",
    "    \n",
    "    # Step 2: Extract Seeds\n",
    "    print(f\"\\n[Step 2] Extracting Diverse Seeds\")\n",
    "    \n",
    "    qaoa_population, qaoa_energies, diversity_metrics = qaoa.extract_diverse_seeds(\n",
    "        population_size=population_size, verbose=verbose\n",
    "    )\n",
    "    \n",
    "    results['diversity_metrics'] = diversity_metrics\n",
    "    results['qaoa_init_energies'] = qaoa_energies.copy()\n",
    "    \n",
    "    # Step 3: QAOA-Seeded MTS\n",
    "    print(f\"\\n[Step 3] Running MTS with QAOA Seeds\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    qaoa_best_seq, qaoa_best_energy, qaoa_final_pop, qaoa_history = memetic_tabu_search(\n",
    "        N=N, population_size=population_size, max_generations=max_generations,\n",
    "        p_mutate=0.3, tabu_iterations=tabu_iterations, initial_population=qaoa_population\n",
    "    )\n",
    "    qaoa_mts_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  QAOA-MTS: best={qaoa_best_energy} in {qaoa_mts_time:.2f}s\")\n",
    "    \n",
    "    results['qaoa_mts_time'] = qaoa_mts_time\n",
    "    results['qaoa_best_energy'] = qaoa_best_energy\n",
    "    results['qaoa_best_seq'] = qaoa_best_seq\n",
    "    results['qaoa_history'] = qaoa_history\n",
    "    results['qaoa_final_pop'] = qaoa_final_pop\n",
    "    \n",
    "    # Step 4: Baseline\n",
    "    print(f\"\\n[Step 4] Running Baseline MTS\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    std_best_seq, std_best_energy, std_final_pop, std_history = memetic_tabu_search(\n",
    "        N=N, population_size=population_size, max_generations=max_generations,\n",
    "        p_mutate=0.3, tabu_iterations=tabu_iterations, initial_population=None\n",
    "    )\n",
    "    std_mts_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  Standard MTS: best={std_best_energy} in {std_mts_time:.2f}s\")\n",
    "    \n",
    "    results['std_mts_time'] = std_mts_time\n",
    "    results['std_best_energy'] = std_best_energy\n",
    "    results['std_best_seq'] = std_best_seq\n",
    "    results['std_history'] = std_history\n",
    "    results['std_final_pop'] = std_final_pop\n",
    "    \n",
    "    improvement = std_best_energy - qaoa_best_energy\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESULTS: QAOA-MTS={qaoa_best_energy}, Standard={std_best_energy}\")\n",
    "    print(f\"Improvement: {improvement} {'(QAOA better)' if improvement > 0 else '(Tie or Random better)'}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    results['N'] = N\n",
    "    results['p'] = p\n",
    "    results['improvement'] = improvement\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-improved",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "N_experiment = 12\n",
    "p_qaoa = 1\n",
    "\n",
    "results = qaoa_enhanced_mts(\n",
    "    N=N_experiment,\n",
    "    p=p_qaoa,\n",
    "    population_size=15,\n",
    "    max_generations=25,\n",
    "    qaoa_shots=800,\n",
    "    tabu_iterations=40,\n",
    "    alpha=0.2,\n",
    "    objective='cvar',\n",
    "    coarse_grid=8,\n",
    "    fine_grid=5,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
